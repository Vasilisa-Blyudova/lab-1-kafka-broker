{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of [Full IMDb Movies Data](https://www.kaggle.com/datasets/anandshaw2001/imdb-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install all necessary dependencies using pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:01:59.297940Z",
     "start_time": "2025-02-23T02:01:58.843920Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:01:58.830360Z",
     "start_time": "2025-02-23T02:01:58.009737Z"
    },
    "id": "L46QTUZtKzo1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import kagglehub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the original dataset from [Kaggle](https://www.kaggle.com/datasets/anandshaw2001/imdb-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_datatest_path = kagglehub.dataset_download(\"anandshaw2001/imdb-data\")\n",
    "print(f\"Original dataset path: {original_datatest_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:02:02.196673Z",
     "start_time": "2025-02-23T02:01:59.375968Z"
    },
    "id": "GEV7v3DpKzo2"
   },
   "outputs": [],
   "source": [
    "original_dataset = pd.read_csv(\n",
    "    f\"{original_datatest_path}/Imdb Movie Dataset.csv\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "original_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`vote_average` is the target column. To prepare the dataset for classification of the rating, convert the column to `int`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:02:02.390610Z",
     "start_time": "2025-02-23T02:02:02.233721Z"
    }
   },
   "outputs": [],
   "source": [
    "original_dataset['target'] = original_dataset['vote_average'].apply(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:02:05.334129Z",
     "start_time": "2025-02-23T02:02:05.134004Z"
    }
   },
   "outputs": [],
   "source": [
    "original_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete all columns containing text attributes in order to continue using standard approaches for tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:02:05.456940Z",
     "start_time": "2025-02-23T02:02:05.446952Z"
    },
    "id": "ukwDBGCaKzo4"
   },
   "outputs": [],
   "source": [
    "original_dataset.drop(\n",
    "    columns=[\n",
    "        \"title\",\n",
    "        \"imdb_id\",\n",
    "        \"original_language\",\n",
    "        \"original_title\",\n",
    "        \"overview\",\n",
    "        \"tagline\",\n",
    "        \"genres\",\n",
    "        \"production_companies\",\n",
    "        \"production_countries\",\n",
    "        \"spoken_languages\",\n",
    "        \"keywords\"\n",
    "    ],\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show columns with `nan` values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:02:05.509533Z",
     "start_time": "2025-02-23T02:02:05.486487Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 837
    },
    "id": "6QPx8QIsKzo5",
    "outputId": "14f45849-f164-4775-eac2-4e4a447b0862"
   },
   "outputs": [],
   "source": [
    "original_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicates and omissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:02:05.663160Z",
     "start_time": "2025-02-23T02:02:05.559925Z"
    }
   },
   "outputs": [],
   "source": [
    "original_dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:02:05.800621Z",
     "start_time": "2025-02-23T02:02:05.676967Z"
    }
   },
   "outputs": [],
   "source": [
    "original_dataset.dropna(inplace=True)\n",
    "original_dataset.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:02:05.830956Z",
     "start_time": "2025-02-23T02:02:05.810255Z"
    }
   },
   "outputs": [],
   "source": [
    "original_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of numeric features and the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59bsNeWGKzo5"
   },
   "source": [
    "### Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7_7WQ_EKzo5"
   },
   "source": [
    "Build distribution of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:02:05.886043Z",
     "start_time": "2025-02-23T02:02:05.881953Z"
    }
   },
   "outputs": [],
   "source": [
    "original_dataset['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:02:06.042741Z",
     "start_time": "2025-02-23T02:02:05.917584Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "xfOHemkEKzo5",
    "outputId": "3211e2e2-22f0-4597-a0a6-d429bf45aeb5"
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=original_dataset, x='target', stat='proportion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYDNT4hhKzo6"
   },
   "source": [
    "The target variable contains a serious imbalance. Let's perform a simple balancing of the dataset, reducing the volume of classes 0, 5, 6 to 25,000 objects (since in this laboratory the requirement for the volume of the dataset is >100,000 objects and we can sacrifice the volume in order not to create a large amount of artificial data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:02:06.068761Z",
     "start_time": "2025-02-23T02:02:06.056803Z"
    }
   },
   "outputs": [],
   "source": [
    "target_counts = [0, 5, 6]\n",
    "new_indices = []\n",
    "\n",
    "for target in target_counts:\n",
    "    indices = np.where(original_dataset[\"target\"] == target)[0]\n",
    "    sampled_indices = np.random.choice(indices, 25000, replace=False)\n",
    "    new_indices.extend(sampled_indices)\n",
    "\n",
    "new_indices = np.array(new_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:02:06.088904Z",
     "start_time": "2025-02-23T02:02:06.072300Z"
    }
   },
   "outputs": [],
   "source": [
    "mask = ~original_dataset[\"target\"].isin(target_counts)\n",
    "train_data = pd.concat([original_dataset.iloc[new_indices], original_dataset[mask]])\n",
    "train_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:02:06.101788Z",
     "start_time": "2025-02-23T02:02:06.099105Z"
    }
   },
   "outputs": [],
   "source": [
    "original_dataset[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:02:06.199009Z",
     "start_time": "2025-02-23T02:02:06.128832Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=original_dataset, x='target', stat='proportion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, we have a more uniform distribution of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9pW-GAEKzo6"
   },
   "source": [
    "## Feature `adult`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:02:06.224132Z",
     "start_time": "2025-02-23T02:02:06.221399Z"
    }
   },
   "outputs": [],
   "source": [
    "original_dataset[\"adult\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the feature to `int` type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:02:06.244433Z",
     "start_time": "2025-02-23T02:02:06.242499Z"
    }
   },
   "outputs": [],
   "source": [
    "original_dataset['adult'] = original_dataset['adult'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3r8EvhQKzo6"
   },
   "source": [
    "## Feature `status`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:02:06.373061Z",
     "start_time": "2025-02-23T02:02:06.281844Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650
    },
    "id": "d_0PT1iUKzo7",
    "outputId": "ab61b7f7-c30f-4ca9-bf22-8969366dcf48"
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=original_dataset, x='status', stat='proportion')\n",
    "plt.ylim((0,1))\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the fact that the distribution of the feature is uneven, we will leave it in order to further analyze its significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature `release_date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:02:06.831892Z",
     "start_time": "2025-02-23T02:02:06.812705Z"
    }
   },
   "outputs": [],
   "source": [
    "original_dataset[\"release_date\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unifying the date type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:02:07.000161Z",
     "start_time": "2025-02-23T02:02:06.844672Z"
    }
   },
   "outputs": [],
   "source": [
    "original_dataset[\"release_date\"] = pd.to_datetime(original_dataset[\"release_date\"], errors=\"coerce\")\n",
    "original_dataset[\"release_date\"].isnull().sum()\n",
    "original_dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my opinion, the month and day of the film's release are mostly noise, so let's leave only the sign with the year of the film's release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:02:10.146252Z",
     "start_time": "2025-02-23T02:02:10.134688Z"
    }
   },
   "outputs": [],
   "source": [
    "original_dataset[\"release_year\"] = original_dataset[\"release_date\"].dt.year\n",
    "original_dataset.drop(columns=\"release_date\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XG0m5MzgKzo9"
   },
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:02:40.070884Z",
     "start_time": "2025-02-23T02:02:40.055203Z"
    }
   },
   "outputs": [],
   "source": [
    "#  Divide dataset into a training and a test sample, so that all KFold validation can be done on a small test sample, and the final model can be trained on a training one.\n",
    "train_dataset, test_dataset = train_test_split(original_dataset, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kfiDMJ0Kzo-"
   },
   "source": [
    "Using the `KFold' (k=10) cross-validation, we select the model. We will use `OneHotEncoding` as a way to encode features.\n",
    "\n",
    "| Models |\n",
    "|----------|\n",
    "| `LogisticRegression` |\n",
    "| `DecisionTreeClassifier` |\n",
    "| `RandomForestClassifier` |\n",
    "| `GradientBoostingClassifier` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T01:50:20.286355Z",
     "start_time": "2025-02-23T01:50:20.282501Z"
    },
    "id": "I13eKWX4Kzo-"
   },
   "outputs": [],
   "source": [
    "x = test_dataset.drop(columns='target')\n",
    "y = np.array(test_dataset['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T01:50:20.752865Z",
     "start_time": "2025-02-23T01:50:20.750061Z"
    }
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T01:51:37.274380Z",
     "start_time": "2025-02-23T01:50:21.726243Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8jkDPmtcKzo-",
    "outputId": "f8ef8fc1-69f3-4d6c-de31-7b37bf1e8b21"
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression': lambda: LogisticRegression(max_iter=500),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier,\n",
    "    'RandomForestClassifier': RandomForestClassifier,\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier\n",
    "}\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "encoder_method = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('ohe', encoder_method, ['status']),\n",
    "], remainder=\"passthrough\")\n",
    "\n",
    "for train_index, val_index in kf.split(x):\n",
    "    x_train, y_train = x.iloc[train_index, :], y[train_index]\n",
    "    x_val, y_val = x.iloc[val_index, :], y[val_index]\n",
    "\n",
    "    for model_name, model_creator in models.items():\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('ohe', column_transformer),\n",
    "            ('scaling', StandardScaler()),\n",
    "            ('model', model_creator())\n",
    "        ])\n",
    "\n",
    "        pipeline.fit(x_train, y_train)\n",
    "        f1 = f1_score(y_val, pipeline.predict(x_val), average='weighted')\n",
    "\n",
    "        if model_name not in metrics:\n",
    "            metrics[model_name] = []\n",
    "        metrics[model_name].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T01:51:37.314818Z",
     "start_time": "2025-02-23T01:51:37.309033Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "LLIe1M6CKzo-",
    "outputId": "5105b637-5b66-495d-f56a-4b65d5d4c394"
   },
   "outputs": [],
   "source": [
    "for experiment in metrics:\n",
    "    metrics[experiment]=np.mean(metrics[experiment])\n",
    "pd.DataFrame.from_dict(metrics, orient='index').rename(columns={0: 'f1 score'}).sort_values(by='f1 score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "363ylwJxKzo-"
   },
   "source": [
    "We will use 2 best models: `GradientBoostingClassifier` Ð¸ `DecisionTreeClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIaJ2BNcKzo-"
   },
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T01:51:37.963872Z",
     "start_time": "2025-02-23T01:51:37.936645Z"
    },
    "id": "SnevFl2RKzo_",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"), ['status']),\n",
    "], remainder=\"passthrough\")\n",
    "column_transformer.fit(x, y)\n",
    "x = pd.DataFrame(column_transformer.transform(x), columns=column_transformer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T01:51:37.990946Z",
     "start_time": "2025-02-23T01:51:37.988403Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zm7TT3DkKzo_",
    "outputId": "6eb8bad0-678f-4b82-eb2b-eae4142e069f"
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbxAyKVVKzo_"
   },
   "source": [
    "At the moment, we have quite a large number of signs. Let's try to select the most important features by the weights of the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T01:51:38.941911Z",
     "start_time": "2025-02-23T01:51:38.058270Z"
    },
    "id": "8p-26pnsKzo_"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('regression', LogisticRegression(max_iter=500))\n",
    "])\n",
    "pipeline.fit(x, y)\n",
    "coef = pipeline.steps[1][1].coef_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CrChXGaKzpA"
   },
   "source": [
    "We visualize the absolute values of the weights of the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T01:51:39.978499Z",
     "start_time": "2025-02-23T01:51:39.893593Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "id": "hAz-BztrKzpA",
    "outputId": "a515cee1-117e-406d-f867-63cdb37fcffe"
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=pd.DataFrame.from_dict({'importance': np.abs(coef), 'feature': x.columns}), x='feature', y='importance')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4TUWaUIKzpA"
   },
   "source": [
    "We will select features that have $importance > C$, where $C$ is some kind of threshold. Using the `k-Fold' (k=10) cross-validation, we will find such a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T01:53:09.954342Z",
     "start_time": "2025-02-23T01:51:40.008903Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DnurhVl5KzpA",
    "outputId": "0cde5019-a172-4cd5-c44f-0c07f68849d3"
   },
   "outputs": [],
   "source": [
    "f1 = {i: [] for i in sorted(np.abs(coef))[:-1]}\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, val_index in tqdm(kf.split(x)):\n",
    "    for C in f1:\n",
    "        X_train = x.iloc[train_index, np.abs(coef) > C]\n",
    "        y_train = y[train_index]\n",
    "        X_val = x.iloc[val_index, np.abs(coef) > C]\n",
    "        y_val = y[val_index]\n",
    "\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('scaling', StandardScaler()),\n",
    "            ('regression', LogisticRegression(max_iter=500, solver='lbfgs'))\n",
    "        ])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        f1[C].append(f1_score(y_val, pipeline.predict(X_val), average='weighted'))\n",
    "\n",
    "for C in f1:\n",
    "    f1[C] = np.mean(f1[C])\n",
    "\n",
    "f1 = pd.DataFrame.from_dict(f1, orient='index').reset_index().rename(columns={'index': 'C', 0: 'f2-score'})\n",
    "\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T01:53:10.476872Z",
     "start_time": "2025-02-23T01:53:10.422513Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "id": "Bfzo44ogKzpA",
    "outputId": "4688d197-f40a-4512-e7a1-98717b58a20a"
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data=f1, x='C', y='f2-score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iGBwxgDKzpA"
   },
   "source": [
    "It can be seen that at $0<C<0.3$ chaotic fluctuations occur. Let's take the threshold of $C=0.3$, after which the quality of the model begins to deteriorate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T01:53:10.969023Z",
     "start_time": "2025-02-23T01:53:10.965729Z"
    },
    "id": "ma59kwCkKzpB"
   },
   "outputs": [],
   "source": [
    "x = x.iloc[:, np.abs(coef)>0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T01:53:11.913291Z",
     "start_time": "2025-02-23T01:53:11.910071Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yWgQl7G9KzpB",
    "outputId": "7f3c510c-0643-4abd-c06b-8822da293491"
   },
   "outputs": [],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2GfKwFnKzpB"
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGS107ZmKzpG"
   },
   "source": [
    "Since we have selected the best models and selected the features, we can see what quality we get now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T01:59:14.092226Z",
     "start_time": "2025-02-23T01:53:13.024807Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvnBnT-_KzpG",
    "outputId": "93584f67-ce0b-46fc-e92f-42471fdaa309"
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier,\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier\n",
    "}\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "for train_index, val_index in kf.split(x):\n",
    "    for model in models:\n",
    "        X_train = x.iloc[train_index, :]\n",
    "        y_train = y[train_index]\n",
    "        X_val = x.iloc[val_index, :]\n",
    "        y_val = y[val_index]\n",
    "\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('scaling', StandardScaler()),\n",
    "            ('classifier', models[model]())\n",
    "        ])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        if model not in metrics:\n",
    "            metrics[model] = []\n",
    "        \n",
    "        f1 = f1_score(y_val, pipeline.predict(X_val), average='weighted')\n",
    "        metrics[model].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T01:59:14.467438Z",
     "start_time": "2025-02-23T01:59:14.464412Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "qOj2YzuzKzpG",
    "outputId": "336fe92a-08f9-4e0a-f5ff-82d02aa426d7"
   },
   "outputs": [],
   "source": [
    "for experiment in metrics:\n",
    "    metrics[experiment]=np.mean(metrics[experiment])\n",
    "pd.DataFrame.from_dict(metrics, orient='index').rename(columns={0: 'f1 score'}).sort_values(by='f1 score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We are training the final GradientBoostingClassifier model, which proved to be the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:03:25.376103Z",
     "start_time": "2025-02-23T02:03:25.359323Z"
    }
   },
   "outputs": [],
   "source": [
    "final_train_dataset, final_test_dataset = train_test_split(train_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train = final_train_dataset.drop(columns='target')\n",
    "y_train = np.array(final_train_dataset['target'])\n",
    "\n",
    "x_test = final_test_dataset.drop(columns='target')\n",
    "y_test = np.array(final_test_dataset['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:03:25.813373Z",
     "start_time": "2025-02-23T02:03:25.809135Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:03:25.863763Z",
     "start_time": "2025-02-23T02:03:25.823387Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_method = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('ohe', encoder_method, ['status']),\n",
    "], remainder=\"passthrough\")\n",
    "column_transformer.fit(x_train, y_train)\n",
    "x_train = pd.DataFrame(column_transformer.transform(x_train), columns=column_transformer.get_feature_names_out())\n",
    "\n",
    "x_test = pd.DataFrame(column_transformer.transform(x_test), columns=column_transformer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:03:25.888593Z",
     "start_time": "2025-02-23T02:03:25.883240Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:03:25.901413Z",
     "start_time": "2025-02-23T02:03:25.897723Z"
    }
   },
   "outputs": [],
   "source": [
    "columns_to_remove = [\"ohe__status_In Production\", \"ohe__status_Planned\", \"ohe__status_Rumored\", \"remainder__runtime\", \"remainder__adult\", \"remainder__release_year\"]\n",
    "x_train.drop(columns=columns_to_remove, inplace=True)\n",
    "x_test.drop(columns=columns_to_remove, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:03:25.966544Z",
     "start_time": "2025-02-23T02:03:25.954245Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:04:39.594028Z",
     "start_time": "2025-02-23T02:03:25.975077Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = GradientBoostingClassifier()\n",
    "\n",
    "classifier.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:06:14.483794Z",
     "start_time": "2025-02-23T02:06:14.463579Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "encoder_filename = 'model/encoder.joblib'\n",
    "scaler_filename = 'model/scaler.joblib'\n",
    "model_filename = 'model/classifier.joblib'\n",
    "\n",
    "if not os.path.exists('model'):\n",
    "    os.makedirs('model')\n",
    "\n",
    "joblib.dump(column_transformer, encoder_filename)\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "joblib.dump(classifier, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:05:09.819141Z",
     "start_time": "2025-02-23T02:05:09.574265Z"
    }
   },
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, classifier.predict(x_test_scaled), average='weighted')\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
